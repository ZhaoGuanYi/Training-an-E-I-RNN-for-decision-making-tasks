{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bce8cf2",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceptual_discrimination import PerceptualDiscrimination\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import os\n",
    "from EI_RNN import Net, compute_loss, accuracy\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d9f6a",
   "metadata": {},
   "source": [
    "## Generate Training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32baad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 任务参数 --\n",
    "dt= 10 # time step in ms\n",
    "tau = 100 # time constant in ms\n",
    "T = 2000 # total time in ms\n",
    "N_batch = 64 # batch size\n",
    "coherence = [0, 0.05,0.1, 0.15, 0.2, 0.3, 0.5, 0.7]\n",
    "\n",
    "task = PerceptualDiscrimination(dt, tau, T, N_batch, coherence=coherence)\n",
    "print(\"task loaded\")\n",
    "\n",
    "dt= 10 # time step in ms\n",
    "tau = 100 # time constant in ms\n",
    "T = 2000 # total time in ms\n",
    "N_batch1 = 200 # batch size\n",
    "task_val = PerceptualDiscrimination(dt, tau, T, N_batch1,coherence=coherence)\n",
    "print(\"val_task loaded\")\n",
    "\n",
    "device = 'cpu'\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c779ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, mask, trial_params = task.get_trial_batch()\n",
    "network_params = task.get_task_params()\n",
    "print(network_params)\n",
    "print(f\"x shape:{x.shape}, y shape: {y.shape}, mask shape: {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ea858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,3), sharey=False)\n",
    "sample_index = 4\n",
    "\n",
    "time_input = range(0, len(x[sample_index,:,:])*dt, dt)\n",
    "time_output = range(0, len(y[sample_index,:,:])*dt, dt)\n",
    "mask_sample = mask[sample_index,:,:].mean(axis=-1)  # shape: [time]\n",
    "masked_indices = np.where(mask_sample > 0)[0]\n",
    "if len(masked_indices) > 0:\n",
    "    xmin = masked_indices[0] * dt\n",
    "    xmax = masked_indices[-1] * dt\n",
    "\n",
    "axes[0].plot(time_input, x[sample_index,:,:])\n",
    "axes[0].set_ylabel(\"Input Magnitude\")\n",
    "axes[0].set_xlabel(\"Time (ms)\")\n",
    "axes[0].set_title(f\"Input(coherece={trial_params[sample_index]['coherence']})\")\n",
    "axes[0].axvspan(xmin, xmax, facecolor='silver', alpha=0.5)\n",
    "\n",
    "axes[1].plot(time_output, y[sample_index,:,:])\n",
    "axes[1].set_ylabel(\"Output\")\n",
    "axes[1].set_xlabel(\"Time (ms)\")\n",
    "axes[1].set_title(\"Output Data\")\n",
    "axes[1].axvspan(xmin, xmax, facecolor='silver', alpha=0.5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4f392",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57237ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define save path\n",
    "save_root = \"./savemodels/\"\n",
    "os.makedirs(save_root, exist_ok=True) # 如果不存在则创建，不会报错\n",
    "\n",
    "# -- 模型参数 --\n",
    "epoch_num = 2500  # 调试用可先设小一点\n",
    "hidden_size = 50 # 隐藏层大小\n",
    "lr = 5e-3 # 学习率\n",
    "l1_lambda = 1e-4  # L1正则化系数\n",
    "\n",
    "mode = 'none'  # 'dense', 'block', o`r 'none' \n",
    "model = Net(input_size=2, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=2, dt=dt, \n",
    "            sigma_rec=0.15,\n",
    "            mode=mode,\n",
    "            noneg=True, \n",
    "            with_Tanh=False).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                       factor=0.5, patience=5)\n",
    "best_loss = float('inf')\n",
    "best_state_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epoch_num + 1):\n",
    "    x, y, mask, _ = task.get_trial_batch()\n",
    "\n",
    "    model.train()\n",
    "    x = torch.tensor(x, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "    y = torch.tensor(y, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "    mask = torch.tensor(mask, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "\n",
    "    y_pred, _ = model(x)\n",
    "\n",
    "    loss = compute_loss(y_pred, y, mask)\n",
    "    \n",
    "    # ---- add L1 ----\n",
    "    # l1_norm = sum(param.abs().sum() for name, param in model.named_parameters() if 'h2h.weight' in name)\n",
    "    # loss = loss + l1_lambda * l1_norm\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0 or epoch==1:\n",
    "        model.eval()\n",
    "        x, y, mask, _ = task_val.get_trial_batch()\n",
    "        x = torch.tensor(x, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "        y = torch.tensor(y, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred, _ = model(x)\n",
    "            val_loss = compute_loss(y_pred, y, mask)\n",
    "            acc = accuracy(y_pred, y, mask)\n",
    "\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"[{lr=} | {hidden_size=} | Epoch {epoch}] Train-val_Loss: {loss.item():.4f}- {val_loss.item():.4f}, Acc: {acc:.3f}\")\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if val_loss.item() < best_loss:\n",
    "                best_loss = val_loss.item()\n",
    "                best_state_dict = model.state_dict()\n",
    "                \n",
    "                model_path = f\"{save_root}{mode}model_lr{lr:.0e}_hidden{hidden_size}_loss{best_loss:.4f}.pt\"\n",
    "                torch.save(best_state_dict, model_path)\n",
    "                print(f\"✅ Best model for hidden_size={hidden_size} saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3d67b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt= 10 # time step in ms\n",
    "tau = 100 # time constant in ms\n",
    "T = 2000 # total time in ms\n",
    "N_batch = 500 # batch size\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "print(\"loading task\")\n",
    "task_test = PerceptualDiscrimination(dt, tau, T, N_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078653f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "mode = 'none'  # 'dense', 'block', o`r 'none'\n",
    "net = Net(input_size=2, hidden_size=hidden_size, \n",
    "            output_size=2, dt=dt, sigma_rec=0.15,mode=mode,noneg=False,with_Tanh=False).to(device)\n",
    "model_path = r\"muti_models4_noneg\\nonemodel_lr1e-04_hidden50_loss0.0093.pt\"\n",
    "net.load_state_dict(torch.load(model_path,map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "# 使用测试数据\n",
    "x_test, y_test, mask_test, trial_params = task_test.get_trial_batch()\n",
    "test_inputs = torch.tensor(x_test, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "test_targets = torch.tensor(y_test, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "test_masks = torch.tensor(mask_test, dtype=torch.float32).permute(1, 0, 2).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_outputs,rnn_activity = net(test_inputs)\n",
    "    test_acc = accuracy(test_outputs, test_targets, test_masks)\n",
    "\n",
    "print(f\"[Best Model] Test Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdef8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "idx = 9\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(range(0, len(test_inputs.cpu().numpy()[:,idx,:])*dt,dt), test_inputs.cpu().numpy()[:,idx,:])\n",
    "plt.ylabel(\"Input Magnitude\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.title(\"Input Data\")\n",
    "plt.legend([\"Input Channel 1\", \"Input Channel 2\"])\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.plot(range(0, len(test_outputs.cpu().numpy()[:,idx,:])*dt,dt),test_outputs.cpu().numpy()[:,idx,:])\n",
    "plt.ylabel(\"Activity of Output Unit\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.title(\"Output on New Sample\")\n",
    "plt.legend([\"Output Channel 1\", \"Output Channel 2\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
